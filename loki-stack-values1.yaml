prometheus:
  enabled: true
  server:
    replicaCount: 2
    ## Server Deployment Strategy type
    #strategy:
    #  type: RollingUpdate #Recreate
    statefulSet:
      enabled: true
    #service:
      #statefulsetReplica:
      #  enabled: true
      #  replica: 2
  isDefault: false
  url: http://{{ include "prometheus.fullname" .}}:{{ .Values.prometheus.server.service.servicePort }}{{ .Values.prometheus.server.prefixURL }}
  datasource:
    jsonData: "{}"
  tolerations:
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Exists"
    effect: "NoSchedule"
  # Sub-chart loki-stack - charts - prometheus - alertmanager
  #https://github.com/prometheus-community/helm-charts/tree/main/charts/alertmanager
  alertmanager:
    enabled: true
    replicaCount: 2
    config:
      receivers:
      - name: 'telegram'
        telegram_configs:
        - bot_token: "7953385693:AAHPVau07SF7I-E3iXsL8N3EC5vl9zZpQns"
          chat_id: 630538347
      route:        
        receiver: 'telegram'  # Резервный получатель (может быть пустым)
        routes:
        - receiver: 'telegram'  # Основной получатель для важных алертов
          group_wait: 10s
          matchers:
          - severity=~"warning|critical"        
  serverFiles:
    alerting_rules.yml:
      groups:
      - name: Prometheus self-monitoring
        rules:
        - alert: NodeDown
          expr: up{job="kubernetes-nodes"} == 0
          for: 1m
          labels:
            severity: critical
          annotations:
            summary: "Node down (instance {{ $labels.instance }})"
            description: "Node {{ $labels.instance }} has been down for more than 5 minutes."
      - name: Logs Loki
        groups:    
        - name: nextcloud-alerts
          rules:
          - alert: NextcloudLoginAttempt
            expr: count_over_time({app="nextcloud"} |= `GET /login?direct=1&user=` [5m]) > 0
            labels:
              severity: warning
            annotations:
              summary: "Nextcloud login attempt detected"
              description: "Detected login attempt in Nextcloud: {{ $labels.instance }} - {{ printf \"%.1000s\" (index (index .Alerts 0).Annotations \"log_message\") }}"
              log_message: '{{ reReplaceAll "\n" " " (index (index .Alerts 0).Labels "log") }}'

loki:
  enabled: true
  replicas: 2
  isDefault: true
  url: http://{{(include "loki.serviceName" .)}}:{{ .Values.loki.service.port }}
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  datasource:
    jsonData: "{}"
    uid: ""

promtail:
  enabled: true
  config:
    logLevel: info
    serverPort: 3101
    clients:
      - url: http://{{ .Release.Name }}:3100/loki/api/v1/push
  tolerations:
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Exists"
    effect: "NoSchedule"

grafana:
  enabled: true 
  useStatefulSet: true
  #replicas: 2
  sidecar:
    datasources:
      label: ""
      labelValue: ""
      enabled: true
      maxLines: 1000
  image:
    tag: 10.0.2
  persistence:
    type: pvc
    enabled: true
    # storageClassName: default
    accessModes:
      - ReadWriteOnce
    size: 3Gi
  dashboardProviders:
   dashboardproviders.yaml:
     apiVersion: 1
     providers:
     - name: 'default'
       orgId: 1
       folder: ''
       type: file
       disableDeletion: false
       editable: true
       options:
         path: /var/lib/grafana/dashboards/default

  dashboardsConfigMaps:
    default: "grafana-dashboards"

  #dashboards:
  #  default:
  #    custom-dashboard:
  #      file: "grafana-dashboards/6417_rev1 (Kubernetes Cluster (Prometheus)).json"
  #    local-dashboard:
  #      url: "https://raw.githubusercontent.com/Luchik51/otus/refs/heads/logging/grafana-dashboards/747_rev2%20(Kubernetes%20Pod%20Metrics).json"